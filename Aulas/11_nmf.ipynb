{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1\n",
    "*Objetivo: explicar o que é uma matriz de documentos por palavras*\n",
    "\n",
    "No código a seguir:\n",
    "\n",
    "1. O que significa cada linha e cada coluna que compõe a matriz x que foi impressa? \n",
    "1. Existem palavras que, de acordo com a matriz x, tipicamente aparecem juntas em documentos deste corpus? Quais são?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto1 = \"adoro festa junina\"\n",
    "texto2 = \"odeio festa junina\"\n",
    "texto3 = \"big brother brasil é legal\"\n",
    "texto4 = \"big brother brasil é chato\"\n",
    "corpus = [texto1, texto2, texto3, texto4]\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2\n",
    "*Objetivo: explicar o que é uma decomposição com perdas*\n",
    "\n",
    "Em nosso corpus, temos duas categorias de textos: os que falam de festa junina e os que falam de big brother brasil. \n",
    "\n",
    "1. Como seria um vetor correspondente a um documento que tipicamente fala de festa junina?\n",
    "1. E o correspondente a um documento que tipicamente fala de big brother brasil?\n",
    "1. Se usássemos somente esses vetores típicos para cada categoria, ao invés dos documentos em si, que tipo de informação nós conservamos? Que tipo de informação nós perdemos?\n",
    "1. Ao decompor nossos documentos em vetores prototípicos, houve perda de informação? Justifique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 3\n",
    "*Objetivo: aplicar a representação matricial*\n",
    "\n",
    "Em nosso processo de decomposição, partimos de uma matriz X, que é de documentos ($d$) por palavras ($p$), ou: $X_{d,p}$\n",
    "\n",
    "Vamos decompor essa matriz em duas outras matrizes. A primeira delas relaciona documentos a tópicos: $B_{d,t}$\n",
    "\n",
    "Idealmente, qual deveria ser o conteúdo da matriz B em nosso caso?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 4\n",
    "*Objetivo: modelar matematicamente a decomposição usando álgebra matricial*\n",
    "\n",
    "Na decomposição, gostaríamos de encontrar duas matrizes que, se forem multiplicadas, podem gerar novamente a matriz original. Então, teremos algo como:\n",
    "$X_{d,p}=B_{d,t} A_{?,?}$\n",
    "\n",
    "1. Quais devem ser obrigatoriamente as dimensões da matriz A, para que a multiplicação BA seja válida e gere uma matriz com as dimensões de X?\n",
    "1. O que significa cada elemento da matriz A?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 5\n",
    "*Objetivo: explicar o erro na decomposição com perdas*\n",
    "\n",
    "Na decomposição $X=BA$, existem casos em que a multiplicação $BA$ pode não ser igual a $X$. Nesse caso, definimos um erro:\n",
    "\n",
    "$$\n",
    "e = ||X-BA||^2\n",
    "$$\n",
    "\n",
    "Sabemos que o número de documentos ($d$) e de palavras ($p$) depende somente do dataset, isto é, temos controle apenas sobre o número de tópicos $t$.\n",
    "\n",
    "Como o valor de $e$ deve se comportar em relação ao valor de $t$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 6\n",
    "*Objetivo: usar a decomposição do tipo fatoração por matrizes não negativas em nosso toy-corpus*\n",
    "\n",
    "O código abaixo aplica a fatoração por matrizes não-negativas (Non-Negative Matrix Factorization).\n",
    "\n",
    "Ele funciona da seguinte forma:\n",
    "* Recebe X como entrada\n",
    "* Encontra os coeficientes das matrizes $B$ e $A$ minimizando $e = ||X-BA||^2$\n",
    "* Todos os coeficientes devem ser maiores ou iguais a zero\n",
    "\n",
    "\n",
    "1. O que significa o parâmetro n_components? A qual parâmetro ele corresponde na equação do Exercício 4?\n",
    "1. Como devemos interpretar a saída y? A qual parâmetro y corresponde na equação do Exercício 4?\n",
    "1. Os resultados mostrados na saída y correspondem a aquilo que você previu no exercício 3? Por que?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=2, init='nndsvda')\n",
    "y = nmf.fit_transform(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 7\n",
    "*Objetivo: interpretar a representação interna dos componentes em nossa fatoração*\n",
    "\n",
    "Podemos encontrar o último componente restante de nossa fatoração acessando uma variável interna do modelo:\n",
    "`print(nmf.components_)`\n",
    "\n",
    "1. A qual parâmetro da equação do exercício 4 corresponde a matriz em nmf.components_?\n",
    "1. Como devemos interpretar cada um dos parâmetros dela?\n",
    "1. Como seria possível mostrar graficamente o quanto cada palavra participa de cada tópico? (se quiser, veja inspirações em https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nmf.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 8\n",
    "*Objetivo: aplicar o processo de fatoração para visualizar tópicos em uma coleção*\n",
    "\n",
    "Aplique o processo de fatoração por NMF para visualizar, em tópicos, a coleção do IMDB. Use dois tópicos e limite o número de palavras no CountVectorizer em poucas centenas (ou então o NMF vai demorar muito a rodar).\n",
    "\n",
    "Como você interpreta as palavras mais salientes de cada tópico?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/IMDB Dataset.csv').sample(1000)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_palavras = 30\n",
    "n_components = 5\n",
    "vectorizer = CountVectorizer(binary=True, max_features=n_palavras)\n",
    "X = vectorizer.fit_transform(list(df['review']))\n",
    "print(X.shape)\n",
    "nmf = NMF(n_components=n_components, init='nndsvda', max_iter=2000)\n",
    "y = nmf.fit_transform(X.toarray())\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(n_components):\n",
    "    tuplas = [ (y[vectorizer.vocabulary_[i],n], i) for i in vectorizer.vocabulary_.keys() ]\n",
    "    tuplas_ordenadas = sorted(\n",
    "    tuplas, reverse=True) # reverse=True pede uma ordenação em ordem decrescente\n",
    "    palavras = [ t[1] for t in tuplas_ordenadas ]\n",
    "    contagens = [ t[0] for t in tuplas_ordenadas ]\n",
    "    plt.figure(figsize=(14,1))\n",
    "    eixo_x = np.arange(n_palavras)\n",
    "    plt.bar(eixo_x[0:n_palavras], contagens[0:n_palavras])\n",
    "    plt.xticks(eixo_x[0:n_palavras], palavras[0:n_palavras], rotation=70)\n",
    "    plt.title(\"Topico número \" + str(n))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 9\n",
    "*Objetivo: comparar classificadores usando tópicos a classificadores usando palavras*\n",
    "\n",
    "A fatoração faz com que cada palavra seja representada num espaço vetorial de tópicos.\n",
    "\n",
    "Podemos pensar que o espaço vetorial de tópicos pode levar a classificações mais robustas, uma vez que trata-se de um espaço de dimensão mais baixa e cujo significado é compreensível a nós (analistas).\n",
    "\n",
    "Compare o desempenho dos classificadores com e sem NMF usando o código abaixo. Como o desempenho do classificador com NMF se comporta quando aumentamos o número de componentes (isto é, o número de tópicos)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/IMDB Dataset.csv').sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3\n",
    "X_train, X_test, y_train, y_test= train_test_split(df['review'], df['sentiment'], train_size=0.7)\n",
    "classificador = Pipeline([\n",
    "                        ('meu_vetorizador', CountVectorizer(stop_words='english')),\n",
    "                        ('meu_transformador', NMF(n_components=n_components, init='nndsvda', max_iter=2000)),\n",
    "                        ('meu_classificador', LogisticRegression(penalty=None, solver='saga', max_iter=10000))\n",
    "                        ])\n",
    "\n",
    "classificador.fit(X_train,y_train)\n",
    "y_pred = classificador.predict(X_test)\n",
    "acc = accuracy_score(y_pred,y_test)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 10\n",
    "*Objetivo: comparar os classificadores usando NMF e os que não usam*\n",
    "\n",
    "Comparando a pipeline de classificadores usando NMF e sem usar NMF:\n",
    "\n",
    "1. Qual é o tamanho da entrada (dimensão do vetor de entrada) de cada um deles?\n",
    "1. O que significa cada dimensão no vetor de entrada de cada um deles?\n",
    "1. Em que situações cada um deles é vantajoso?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
